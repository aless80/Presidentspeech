{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "# Topic modeling \n",
      "## US Presidents' State of the Union Addresses and Messages\n",
      "Data: http://www.presidency.ucsb.edu/sou.php\n",
      "Inspiration: https://www.exaptive.com/blog/topic-modeling-the-state-of-the-union"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# See Scrape notebook for the scraping. Import the messages stored in the documents list\n",
      "import pickle\n",
      "pkl_file = open('documents_raw.pkl', 'rb')\n",
      "documents_raw = pickle.load(pkl_file)\n",
      "documents_raw[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "u'Thank you very much. Mr. Speaker, Mr. Vice President, Members of Congress, the First Lady of the United States, and citizens of America: Tonight, as we mark the conclusion of our celebration of Black History Month, we are reminded of our Nation\\'s path towards civil rights and the work that still remains to be done. Recent threats targeting Jewish community centers and vandalism of Jewish cemeteries, as well as last week\\'s shooting in Kansas City, remind us that while we may be a nation divided on policies, we are a country that stands united in condemning hate and evil in all of its very ugly forms.  Each American generation passes the torch of truth, liberty, and justice in an unbroken chain, all the way down to the present. That torch is now in our hands, and we will use it to light up the world. I am here tonight to deliver a message of unity and strength, and it is a message deeply delivered from my heart. A new chapter of American greatness is now beginning. A new national pride is sweeping across our Nation. And a new surge of optimism is placing impossible dreams firmly within our grasp.  What we are witnessing today is the renewal of the American spirit. Our allies will find that America is once again ready to lead. All the nations of the world\\u2014friend or foe\\u2014will find that America is strong, America is proud, and America is free.  In 9 years, the United States will celebrate the 250th anniversary of our founding: 250 years since the day we declared our independence. It will be one of the great milestones in the history of the world. But what will America look like as we reach our 250th year? What kind of country will we leave for our children?  I will not allow the mistakes of recent decades past to define the course of our future. For too long, we\\'ve watched our middle class shrink as we\\'ve exported our jobs and wealth to foreign countries. We\\'ve financed and built one global project after another, but ignored the fates of our children in the inner cities of Chicago, Baltimore, Detroit, and so many other places throughout our land.  We\\'ve defended the borders of other nations, while leaving our own borders wide open for anyone to cross and for drugs to pour in at a now unprecedented rate. And we\\'ve spent trillions and trillions of dollars overseas, while our infrastructure at home has so badly crumbled.  Then, in 2016, the Earth shifted beneath our feet. The rebellion started as a quiet protest, spoken by families of all colors and creeds, families who just wanted a fair shot for their children and a fair hearing for their concerns.  But then the quiet voices became a loud chorus, as thousands of citizens now spoke out together, from cities small and large, all across our country. Finally, the chorus became an earthquake, and the people turned out by the tens of millions, and they were all united by one very simple, but crucial demand: that America must put its own citizens first. Because only then can we truly make America great again.  Dying industries will come roaring back to life. Heroic veterans will get the care they so desperately need. Our military will be given the resources its brave warriors so richly deserve. Crumbling infrastructure will be replaced with new roads, bridges, tunnels, airports, and railways gleaming across our very, very beautiful land. Our terrible drug epidemic will slow down and, ultimately, stop. And our neglected inner cities will see a rebirth of hope, safety, and opportunity. Above all else, we will keep our promises to the American people. [Applause] Thank you.  It\\'s been a little over a month since my Inauguration, and I want to take this moment to update the Nation on the progress I\\'ve made in keeping those promises.  Since my election, Ford, Fiat Chrysler, General Motors, Sprint, Softbank, Lockheed, Intel, Walmart, and many others have announced that they will invest billions and billions of dollars in the United States and will create tens of thousands of new American jobs.  The stock market has gained almost $3 trillion in value since the election on November 8\\u2014a record. We\\'ve saved taxpayers hundreds of millions of dollars by bringing down the price of fantastic\\u2014and it is a fantastic\\u2014new F-35 jet fighter, and we\\'ll be saving billions more on contracts all across our Government. We have placed a hiring freeze on nonmilitary and nonessential Federal workers.  We have begun to drain the swamp of government corruption by imposing a 5-year ban on lobbying by executive branch officials and a lifetime ban\\u2014[applause]\\u2014thank you. Thank you. And a lifetime ban on becoming lobbyists for a foreign government.  We have undertaken a historic effort to massively reduce job-crushing regulations, creating a deregulation Task Force inside of every Government agency. And we\\'re imposing a new rule which mandates that for every one new regulation, two old regulations must be eliminated. We\\'re going to stop the regulations that threaten the future and livelihood of our great coal miners.  We have cleared the way for the construction of the Keystone and Dakota Access pipelines, thereby creating tens of thousands of jobs. And I\\'ve issued a new directive that new American pipelines be made with American steel.  We have withdrawn the United States from the job-killing Trans-Pacific Partnership. And with the help of Prime Minister Justin Trudeau, we have formed a council with our neighbors in Canada to help ensure that women entrepreneurs have access to the networks, markets, and capital they need to start a business and live out their financial dreams.  To protect our citizens, I have directed the Department of Justice to form a Task Force on Reducing Violent Crime. I have further ordered the Departments of Homeland Security and Justice, along with the Department of State and the Director of National Intelligence, to coordinate an aggressive strategy to dismantle the criminal cartels that have spread all across our Nation. We will stop the drugs from pouring into our country and poisoning our youth, and we will expand treatment for those who have become so badly addicted.  At the same time, my administration has answered the pleas of the American people for immigration enforcement and border security. By finally enforcing our immigration laws, we will raise wages, help the unemployed, save billions and billions of dollars, and make our communities safer for everyone. We want all Americans to succeed, but that can\\'t happen in an environment of lawless chaos. We must restore integrity and the rule of law at our borders.  For that reason, we will soon begin the construction of a great, great wall along our southern border. As we speak tonight, we are removing gang members, drug dealers, and criminals that threaten our communities and prey on our very innocent citizens. Bad ones are going out as I speak, and as I\\'ve promised throughout the campaign.  To any in Congress who do not believe we should enforce our laws, I would ask you this one question: What would you say to the American family that loses their jobs, their income, or their loved one because America refused to uphold its laws and defend its borders?  Our obligation is to serve, protect, and defend the citizens of the United States. We are also taking strong measures to protect our Nation from radical Islamic terrorism. According to data provided by the Department of Justice, the vast majority of individuals convicted of terrorism and terrorism-related offenses since 9/11 came here from outside of our country. We have seen the attacks at home, from Boston to San Bernardino to the Pentagon, and, yes, even the World Trade Center.  We have seen the attacks in France, in Belgium, in Germany, and all over the world. It is not compassionate, but reckless to allow uncontrolled entry from places where proper vetting cannot occur. Those given the high honor of admission to the United States should support this country and love its people and its values. We cannot allow a beachhead of terrorism to form inside America. We cannot allow our Nation to become a sanctuary for extremists.  That is why my administration has been working on improved vetting procedures, and we will shortly take new steps to keep our Nation safe and to keep those out who will do us harm.  As promised, I directed the Department of Defense to develop a plan to demolish and destroy ISIS, a network of lawless savages that have slaughtered Muslims and Christians, and men and women and children of all faiths and all beliefs. We will work with our allies, including our friends and allies in the Muslim world, to extinguish this vile enemy from our planet.  I have also imposed new sanctions on entities and individuals who support Iran\\'s ballistic missile program and reaffirmed our unbreakable alliance with the State of Israel.  Finally, I have kept my promise to appoint a Justice to the United States Supreme Court, from my list of 20 judges, who will defend our Constitution.  I am greatly honored to have Maureen Scalia with us in the gallery tonight. Thank you, Maureen. Her late, great husband, Antonin Scalia, will forever be a symbol of American justice. To fill his seat, we have chosen Judge Neil Gorsuch, a man of incredible skill and deep devotion to the law. He was confirmed unanimously by the Court of Appeals, and I am asking the Senate to swiftly approve his nomination.  Tonight, as I outline the next steps we must take as a country, we must honestly acknowledge the circumstances we inherited. Ninety-four million Americans are out of the labor force. Over 43 million people are now living in poverty, and over 43 million Americans are on food stamps. More than 1 in 5 people in their prime working years are not working. We have the worst financial recovery in 65 years. In the last 8 years, the past administration has put on more new debt than nearly all of the other Presidents combined.  We\\'ve lost more than one-fourth of our manufacturing jobs since NAFTA was approved, and we\\'ve lost 60,000 factories since China joined the World Trade Organization in 2001. Our trade deficit in goods with the world last year was nearly $800 billion dollars. And overseas we have inherited a series of tragic foreign policy disasters. Solving these and so many other pressing problems will require us to work past the differences of party. It will require us to tap into the American spirit that has overcome every challenge throughout our long and storied history. But to accomplish our goals at home and abroad, we must restart the engine of the American economy, making it easier for companies to do business in the United States, and much, much harder for companies to leave our country.  Right now American companies are taxed at one of the highest rates anywhere in the world. My economic team is developing historic tax reform that will reduce the tax rate on our companies so they can compete and thrive anywhere and with anyone. It will be a big, big cut.  At the same time, we will provide massive tax relief for the middle class. We must create a level playing field for American companies and our workers\\u2014have to do it. Currently, when we ship products out of America, many other countries make us pay very high tariffs and taxes. But when foreign companies ship their products into America, we charge them nothing, or almost nothing.  I just met with officials and workers from a great American company, Harley-Davidson. In fact, they proudly displayed five of their magnificent motorcycles, made in the U.S.A., on the front lawn of the White House. [Laughter] And they wanted me to ride one, and I said, \"No, thank you.\" [Laughter]  At our meeting, I asked them, how are you doing, how is business? They said that it\\'s good. I asked them further, how are you doing with other countries, mainly international sales? They told me\\u2014without even complaining, because they have been so mistreated for so long that they\\'ve become used to it\\u2014that it\\'s very hard to do business with other countries because they tax our goods at such a high rate. They said that in the case of another country, they taxed their motorcycles at 100 percent. They weren\\'t even asking for a change. But I am.  I believe strongly in free trade, but it also has to be fair trade. It\\'s been a long time since we had fair trade. The first Republican President, Abraham Lincoln, warned that the \"abandonment of the protective policy by the American Government will produce want and ruin among our people.\" Lincoln was right, and it\\'s time we heeded his advice and his words. I am not going to let America and its great companies and workers be taken advantage of us any longer. They have taken advantage of our country. No longer.  I am going to bring back millions of jobs. Protecting our workers also means reforming our system of legal immigration. The current, outdated system depresses wages for our poorest workers and puts great pressure on taxpayers. Nations around the world like Canada, Australia, and many others, have a merit-based immigration system. It\\'s a basic principle that those seeking to enter a country ought to be able to support themselves financially. Yet, in America, we do not enforce this rule, straining the very public resources that our poorest citizens rely upon. According to the National Academy of Sciences, our current immigration system costs American taxpayers many billions of dollars a year.  Switching away from this current system of lower skilled immigration, and instead adopting a merit-based system, we will have so many more benefits. It will save countless dollars, raise workers\\' wages, and help struggling families\\u2014including immigrant families\\u2014enter the middle class. And they will do it quickly, and they will be very, very happy, indeed.  I believe that real and positive immigration reform is possible, as long as we focus on the following goals: to improve jobs and wages for Americans, to strengthen our Nation\\'s security, and to restore respect for our laws. If we are guided by the wellbeing of American citizens, then I believe Republicans and Democrats can work together to achieve an outcome that has eluded our country for decades.  Another Republican President, Dwight D. Eisenhower, initiated the last truly great national infrastructure program\\u2014the building of the Interstate Highway System. The time has come for a new program of national rebuilding. America has spent approximately $6 trillion in the Middle East; all the while, our infrastructure at home is crumbling. With this $6 trillion, we could have rebuilt our country twice, and maybe even three times if we had people who had the ability to negotiate. [Laughter]  To launch our national rebuilding, I will be asking Congress to approve legislation that produces a $1 trillion investment in infrastructure of the United States\\u2014financed through both public and private capital\\u2014creating millions of new jobs. This effort will be guided by two core principles: buy American and hire American.  Tonight I am also calling on this Congress to repeal and replace Obamacare with reforms that expand choice, increase access, lower costs, and at the same time, provide better health care.  Mandating every American to buy Government-approved health insurance was never the right solution for our country. The way to make health insurance available to everyone is to lower the cost of health insurance, and that is what we are going do.  Obamacare premiums nationwide have increased by double and triple digits. As an example, Arizona went up 116 percent last year alone. Governor Matt Bevin of Kentucky just said Obamacare is failing in his State\\u2014the State of Kentucky\\u2014and it\\'s unsustainable and collapsing.  One-third of the counties have only one insurer, and they are losing them fast. They are losing them so fast. They are leaving, and many Americans have no choice at all. There\\'s no choice left. Remember when you were told that you could keep your doctor and keep your plan? We now know that all of those promises have been totally broken. Obamacare is collapsing, and we must act decisively to protect all Americans.  Action is not a choice, it is a necessity. So I am calling on all Democrats and Republicans in Congress to work with us to save Americans from this imploding Obamacare disaster.  Here are the principles that should guide the Congress as we move to create a better health care system for all Americans:  First, we should ensure that Americans with preexisting conditions have access to coverage, and that we have a stable transition for Americans currently enrolled in the health care exchanges.  Secondly, we should help Americans purchase their own coverage through the use of tax credits and expanded health savings accounts, but it must be the plan they want, not the plan forced on them by our Government.  Thirdly, we should give our State Governors the resources and flexibility they need with Medicaid to make sure no one is left out.  Fourth, we should implement legal reforms that protect patients and doctors from unnecessary costs that drive up the price of insurance and work to bring down the artificially high price of drugs and bring them down immediately. And finally, the time has come to give Americans the freedom to purchase health insurance across State lines, which will create a truly competitive national marketplace that will bring costs way down and provide far better care. So important.  Everything that is broken in our country can be fixed. Every problem can be solved. And every hurting family can find healing and hope.  Our citizens deserve this and so much more, so why not join forces and finally get the job done, and get it done right? On this and so many other things, Democrats and Republicans should get together and unite for the good of our country and for the good of the American people.  My administration wants to work with members of both parties to make childcare accessible and affordable; to help ensure new parents that they have paid family leave; to invest in women\\'s health; and to promote clean air and clean water; and to rebuild our military and our infrastructure.  True love for our people requires us to find common ground, to advance the common good, and to cooperate on behalf of every American child who deserves a much brighter future.  An incredible young woman is with us this evening, who should serve as an inspiration to us all. Today is Rare Disease Day, and joining us in the gallery is a rare disease survivor, Megan Crowley.  Megan was diagnosed with Pompe disease, a rare and serious illness, when she was 15 months old. She was not expected to live past 5. On receiving this news, Megan\\'s dad John fought with everything he had to save the life of his precious child. He founded a company to look for a cure and helped develop the drug that saved Megan\\'s life. Today she is 20 years old and a sophomore at Notre Dame.  Megan\\'s story is about the unbounded power of a father\\'s love for a daughter. But our slow and burdensome approval process at the Food and Drug Administration keeps too many advances, like the one that saved Megan\\'s life, from reaching those in need. If we slash the restraints, not just at the FDA, but across our Government, then we will be blessed with far more miracles just like Megan. In fact, our children will grow up in a nation of miracles.  But to achieve this future, we must enrich the mind and the souls of every American child. Education is the civil rights issue of our time. I am calling upon members of both parties to pass an education bill that funds school choice for disadvantaged youth, including millions of African American and Latino children. These families should be free to choose the public, private, charter, magnet, religious, or home school that is right for them.  Joining us tonight in the gallery is a remarkable woman, Denisha Merriweather. As a young girl, Denisha struggled in school and failed third grade twice. But then, she was able to enroll in a private center for learning\\u2014great learning center\\u2014with the help of a tax credit and a scholarship program.  Today, she is the first in her family to graduate, not just from high school, but from college. Later this year she will get her master\\'s degree in social work. We want all children to be able to break the cycle of poverty just like Denisha.  But to break the cycle of poverty, we must also break the cycle of violence. The murder rate in 2015 experienced its largest single-year increase in nearly half a century. In Chicago, more than 4,000 people were shot last year alone, and the murder rate so far this year has been even higher. This is not acceptable in our society.  Every American child should be able to grow up in a safe community, to attend a great school, and to have access to a high-paying job. But to create this future, we must work with, not against\\u2014not against\\u2014the men and women of law enforcement. We must build bridges of cooperation and trust, not drive the wedge of disunity, and really, it\\'s what it is\\u2014division. It\\'s pure, unadulterated division. We have to unify.  Police and sheriffs are members of our community. They\\'re friends and neighbors, they\\'re mothers and fathers, sons and daughters, and they leave behind loved ones every day who worry about whether or not they\\'ll come home safe and sound. We must support the incredible men and women of law enforcement.  And we must support the victims of crime. I have ordered the Department of Homeland Security to create an office to serve American victims. The office is called VOICE: Victims of Immigration Crime Engagement. We are providing a voice to those who have been ignored by our media and silenced by special interests. Joining us in the audience tonight are four very brave Americans whose Government failed them. Their names are Jamiel Shaw, Susan Oliver, Jenna Oliver, and Jessica Davis.  Jamiel\\'s 17-year-old son was viciously murdered by an illegal immigrant gang member who had just been released from prison. Jamiel Shaw, Jr. was an incredible young man, with unlimited potential, who was getting ready to go to college where he would have excelled as a great college quarterback. But he never got the chance. His father, who is in the audience tonight, has become a very good friend of mine. Jamiel, thank you. Thank you.  Also with us are Susan Oliver and Jessica Davis. Their husbands, Deputy Sheriff Danny Oliver and Detective Michael Davis, were slain in the line of duty in California. They were pillars of their community. These brave men were viciously gunned down by an illegal immigrant with a criminal record and two prior deportations. Should have never been in our country.  Sitting with Susan is her daughter, Jenna. Jenna, I want you to know that your father was a hero, and that tonight you have the love of an entire country supporting you and praying for you.  To Jamiel, Jenna, Susan, and Jessica: I want you to know that we will never stop fighting for justice. Your loved ones will never, ever be forgotten. We will always honor their memory.  Finally, to keep America safe, we must provide the men and women of the United States military with the tools they need to prevent war. If they must, they have to fight and they only have to win.  I am sending Congress a budget that rebuilds the military, eliminates the defense sequester, and calls for one of the largest increases in national defense spending in American history. My budget will also increase funding for our veterans. Our veterans have delivered for this Nation, and now we must deliver for them.  The challenges we face as a nation are great, but our people are even greater. And none are greater or are braver than those who fight for America in uniform.  We are blessed to be joined tonight by Carryn Owens, the widow of U.S. Navy Special Operator, Senior Chief William \"Ryan\" Owens. Ryan died as he lived: a warrior and a hero, battling against terrorism and securing our Nation. I just spoke to our great General Mattis, just now, who reconfirmed that\\u2014and I quote\\u2014\"Ryan was a part of a highly successful raid that generated large amounts of vital intelligence that will lead to many more victories in the future against our enemy.\" Ryan\\'s legacy is etched into eternity. Thank you. [Applause] And Ryan is looking down, right now\\u2014you know that\\u2014and he is very happy because I think he just broke a record. [Laughter]  For as the Bible teaches us, there is no greater act of love than to lay down one\\'s life for one\\'s friends. Ryan laid down his life for his friends, for his country, and for our freedom. And we will never forget Ryan.  To those allies who wonder what kind of a friend America will be, look no further than the heroes who wear our uniform. Our foreign policy calls for a direct, robust, and meaningful engagement with the world. It is American leadership based on vital security interests that we share with our allies all across the globe.  We strongly support NATO, an alliance forged through the bonds of two world wars that dethroned fascism, and a cold war, and defeated communism.  But our partners must meet their financial obligations. And now, based on our very strong and frank discussions, they are beginning to do just that. In fact, I can tell you, the money is pouring in. Very nice. We expect our partners\\u2014whether in NATO, the Middle East, or in the Pacific\\u2014to take a direct and meaningful role in both strategic and military operations, and pay their fair share of the cost. Have to do that.  We will respect historic institutions, but we will respect the foreign rights of all nations, and they have to respect our rights as a nation also. Free nations are the best vehicle for expressing the will of the people, and America respects the right of all nations to chart their own path. My job is not to represent the world. My job is to represent the United States of America.  But we know that America is better off when there is less conflict, not more. We must learn from the mistakes of the past. We have seen the war and the destruction that have ravaged and raged throughout the world\\u2014all across the world. The only long-term solution for these humanitarian disasters, in many cases, is to create the conditions where displaced persons can safely return home and begin the long, long process of rebuilding.  America is willing to find new friends and to forge new partnerships where shared interests align. We want harmony and stability, not war and conflict. We want peace, wherever peace can be found.  America is friends today with former enemies. Some of our closest allies, decades ago, fought on the opposite side of these terrible, terrible wars. This history should give us all faith in the possibilities for a better world. Hopefully, the 250th year for America will see a world that is more peaceful, more just, and more free.  On our 100th anniversary, in 1876, citizens from across our Nation came to Philadelphia to celebrate America\\'s centennial. At that celebration, the country\\'s builders and artists and inventors showed off their wonderful creations. Alexander Graham Bell displayed his telephone for the first time. Remington unveiled the first typewriter. An early attempt was made at electric light. Thomas Edison showed an automatic telegraph and an electric pen. Imagine the wonders our country could know in America\\'s 250th year. Think of the marvels we can achieve if we simply set free the dreams of our people. Cures to the illnesses that have always plagued us are not too much to hope. American footprints on distant worlds are not too big a dream. Millions lifted from welfare to work is not too much to expect. And streets where mothers are safe from fear, schools where children learn in peace, and jobs where Americans prosper and grow are not too much to ask.  When we have all of this, we will have made America greater than ever before\\u2014for all Americans. This is our vision. This is our mission. But we can only get there together. We are one people with one destiny. We all bleed the same blood. We all salute the same great American flag. And we all are made by the same God.  When we fulfill this vision, when we celebrate our 250 years of glorious freedom, we will look back on tonight as when this new chapter of American greatness began. The time for small thinking is over. The time for trivial fights is behind us. We just need the courage to share the dreams that fill our hearts, the bravery to express the hopes that stir our souls, and the confidence to turn those hopes and those dreams into action.  From now on, America will be empowered by our aspirations, not burdened by our fears; inspired by the future, not bound by failures of the past; and guided by our vision, not blinded by our doubts.  I am asking all citizens to embrace this renewal of the American spirit. I am asking all Members of Congress to join me in dreaming big and bold, and daring things for our country. I am asking everyone watching tonight to seize this moment. Believe in yourselves, believe in your future, and believe, once more, in America.  Thank you, God bless you, and God bless the United States.'"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clean the messages in the documents list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is just the standard example:\n",
      "#from sklearn.datasets import fetch_20newsgroups\n",
      "#dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
      "#documents = dataset.data\n",
      "\n",
      "#Create documents list with tokenized text\n",
      "# Tokenize\n",
      "from nltk.corpus import stopwords \n",
      "import string\n",
      "import re\n",
      "stop = set(stopwords.words('english')) #NB a set is more efficient than a list\n",
      "exclude = set(string.punctuation) \n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "lemma = WordNetLemmatizer()\n",
      "#pstemmer = PorterStemmer()\n",
      "def clean_text(doc, skipWords=[]):\n",
      "    for w in skipWords:\n",
      "        doc = doc.replace(w,'')\n",
      "    #Remove non-letters and convert to lower case\n",
      "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", doc.lower())\n",
      "    #Remove non unicode (accents etc). Remove word that can starts with non letter and ends with non letter. \n",
      "    #\"1st\" \"a2\" \"1a3\" safe, \"1\" \"123\" esta'\" not\n",
      "    #letters_only = re.sub(r'\\W|\\b[^a-z]*[^a-z]\\b', \" \", doc.lower())\n",
      "    letters_only = re.sub(r'\\W|\\b\\w*\\d\\b', ' ', doc.lower())\n",
      "    #Split into individual words and remove stop words\n",
      "    #This can be done in TfidfVectorizer/CountVectorizer but ok..\n",
      "    stop_free = \" \".join([i for i in letters_only.split() if i not in stop])\n",
      "    #Remove punctuations should not be needed after letters_only but who knows\n",
      "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
      "    #Stemming/Lemmatizing\n",
      "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
      "    #normalized = \" \".join(pstemmer.stem(word) for word in punc_free.split())\n",
      "    #Join the words back into one string separated by space\n",
      "    #return( \" \".join(normalized))   \n",
      "    return normalized\n",
      "documents = [clean_text(doc, skipWords=['[Laughter]','[Applause]']) for doc in documents_raw]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Apply [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to documents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Learn the vocabulary dictionary and return term-document matrix.\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
      "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
      "\n",
      "# NMF is able to use tf-idf\n",
      "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3), #strip_accents='ascii', tokenizer=lemma.lemmatize, lowercase=True, \n",
      "                        stop_words='english', max_df=0.9, min_df=0.05, max_features=None)\n",
      "\n",
      "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
      "tf_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,3), #strip_accents='ascii', tokenizer=lemma.lemmatize, lowercase=True, \n",
      "                        stop_words='english',max_df=0.5, min_df=5, max_features=1500)\n",
      "\n",
      "#Fit Transform - Learn the vocabulary dictionary and return term-document matrix\n",
      "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
      "tf = tf_vectorizer.fit_transform(documents)\n",
      "\n",
      "# Get the number of features (ie the number of terms composed of 1 to 3 words)\n",
      "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
      "tf_feature_names = tf_vectorizer.get_feature_names()\n",
      "print(\"The number of features (i.e. terms/N-grams) for NMF is %i\" % len(tfidf_feature_names))\n",
      "print(\"The number of features (i.e. terms/N-grams) for LDA is %i\" % len(tf_feature_names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The number of features (i.e. terms/N-grams) for NMF is 11308\n",
        "The number of features (i.e. terms/N-grams) for LDA is 11308\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### tf_vectorizer.get_feature_names(): map feature indices -> feature name\n",
      "#### lda.components_[i,j] (topic word distribution): \"weights\" of terms j in topic i\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Fit [NMF](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) and [LDA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "no_topics = 6\n",
      "# Run NMF\n",
      "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd')\n",
      "nmf.fit(tfidf)\n",
      "# Run LDA\n",
      "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', \n",
      "                                learning_offset=50., random_state=0, n_jobs=2)\n",
      "lda.fit(tf)\n",
      "\n",
      "# Display the terms in the topics\n",
      "#tf_vectorizer.get_feature_names(): map feature indices -> feature name\n",
      "#lda.components_[i,j] (topic word distribution): \"weights\" of terms j in topic i\n",
      "def display_topics(model, feature_names, no_top_words):\n",
      "    for ind, topic in enumerate(model.components_):\n",
      "        print \"Topic %d:\" % (ind)\n",
      "        print \" \".join([feature_names[i]+' -'\n",
      "                        for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
      "        \n",
      "print \"NMF:\"\n",
      "display_topics(nmf, tfidf_feature_names, no_top_words = 10)\n",
      "print\n",
      "print \"LDA:\"\n",
      "display_topics(lda, tf_feature_names, no_top_words = 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NMF:\n",
        "Topic 0:\n",
        "administration - shall - development - legislation - area - price - defense - energy - resource - international -\n",
        "Topic 1:\n",
        "tonight - care - like - reform - cut - ask - say - thing - college - health care -\n",
        "Topic 2:\n",
        "communist - free nation - soviet - free world - ruler - atomic - defense - aggression - europe - united nation -\n",
        "Topic 3:\n",
        "iraq - terrorist - iraqi - terror - al - qaida - al qaida - saddam - regime - hussein -\n",
        "Topic 4:\n",
        "zone - federal income tax - figure - fighting men - fighting inflation - fighting force - fighting - fighter - fight win - fight war -\n",
        "Topic 5:\n",
        "vietnam - tonight - south vietnam - south - people south - recommend - great society - think - try - conflict -\n",
        "\n",
        "LDA:\n",
        "Topic 0:\n",
        "defense - administration - area - reform - development - international - energy - local - production - tonight -\n",
        "Topic 1:\n",
        "tonight - care - defense - energy - reform - ask - percent - cut - like - challenge -\n",
        "Topic 2:\n",
        "energy - development - legislation - defense - area - administration - assistance - income - reform - responsibility -\n",
        "Topic 3:\n",
        "administration - legislation - energy - development - area - international - reform - major - price - fiscal -\n",
        "Topic 4:\n",
        "tonight - care - cut - worker - thing - trade - energy - administration - legislation - income -\n",
        "Topic 5:\n",
        "energy - administration - legislation - reform - rate - percent - international - level - tonight - challenge -\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### LDA\n",
      "4 topics can be discerned using a quite low cutoff for the words appearing in more than 50% of the documets (max_df=0.5). I played with the parameters and I often got \"bad\" models, i.e. very 'small' a 'degenerate' topic with low or zero token (i.e. word) presence in the corpus. \n",
      "This happens when increasing the number of features to 2000 or more, adding a 5th topic, increasing max_df, etc. The parameter min_df removes words present in less than 5 documents of the corpus. a value of min_df=5 seems fine, it shows more interesting words such as 'oil'.\n",
      "\n",
      "<!---max_features is important. None is bad (one blob). 2000 better than 1000. 3000 2 blobs\n",
      "#3000 and max_df=0.6 instead of 0.9 I get 2.5 blobs. min_df=0.15 instead of 0.05 I get 4 blobs. 3 nice topics. it is no_topics = 4, max_df=0.6, min_df=0.15, max_features=2000)\n",
      "#I try max_df=0.5, min_df=10, max_features=2000 but no\n",
      "#Cannot get 5th topic\n",
      "\n",
      "#LDA\n",
      "#max_df: 0.5. with 0.9 means only 3 real topics. 0.6 is still quite high and 4th topic is small\n",
      "#min_df: 5 is ok, low you get interesting words such as oil\n",
      "#max_features: 1500. 2000/3000 you start losing 4th, most of all if high max_df. rising min_df does not help. 500 loses 4th\n",
      "#?? 5/6 topics with max_df=0.5, min_df=5, max_features=1500. topics slightly small/similar. cannot rise max_df to 0.6\n",
      "--->"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
      "tf_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,3), #token_pattern = r'\\b[a-zA-Z]{3,}\\b',#strip_accents='ascii', tokenizer=lemma.lemmatize, lowercase=True, \n",
      "                        stop_words='english',max_df=0.5, min_df=5, max_features=1500)\n",
      "#Fit Transform - Learn the vocabulary dictionary and return term-document matrix\n",
      "tf = tf_vectorizer.fit_transform(documents)\n",
      "no_topics = 4\n",
      "# Run LDA\n",
      "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50., random_state=0, n_jobs=2)\n",
      "lda.fit(tf)\n",
      "\n",
      "#Plot with pyLDAvis - see http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/sklearn.ipynb\n",
      "import pyLDAvis.sklearn, pyLDAvis\n",
      "pyLDAvis.enable_notebook();\n",
      "pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
      "\n",
      "# Display the terms in the topics\n",
      "#tf_vectorizer.get_feature_names(): map feature indices -> feature name\n",
      "#lda.components_[i,j] (topic word distribution): \"weights\" of terms j in topic i\n",
      "def display_topics(model, feature_names, no_top_words):\n",
      "    for ind, topic in enumerate(model.components_):\n",
      "        print \"Topic %d:\" % (ind)\n",
      "        print \" \".join([feature_names[i]+' -'\n",
      "                        for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
      "        \n",
      "print \"NMF:\"\n",
      "display_topics(nmf, tfidf_feature_names, no_top_words = 10)\n",
      "print\n",
      "print \"LDA:\"\n",
      "display_topics(lda, tf_feature_names, no_top_words = 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named pyLDAvis.sklearn",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-51a3a324cefc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#Plot with pyLDAvis - see http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/sklearn.ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_vectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named pyLDAvis.sklearn"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#NMF max_df=0.5, min_df=5, max_features=1500  ; random_state=1, alpha=.1, l1_ratio=.5     no_topics = 6   \n",
      "#more topics. full topics but clustered\n",
      "#lower min_df clusters more\n",
      "\n",
      "\n",
      "# NMF is able to use tf-idf\n",
      "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3), #strip_accents='ascii', tokenizer=lemma.lemmatize, lowercase=True, \n",
      "                        stop_words='english', max_df=0.5, min_df=15, max_features=1000)\n",
      "#Fit Transform - Learn the vocabulary dictionary and return term-document matrix\n",
      "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
      "no_topics = 5\n",
      "# Run NMF\n",
      "nmf = NMF(n_components=no_topics, random_state=0, alpha=.1, l1_ratio=.5, init='nndsvd')\n",
      "nmf.fit(tfidf)\n",
      "\n",
      "#See http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/sklearn.ipynb\n",
      "import pyLDAvis.sklearn, pyLDAvis\n",
      "pyLDAvis.enable_notebook();\n",
      "pyLDAvis.sklearn.prepare(nmf, tfidf, tfidf_vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-08-04 16:14:17.565189. Please add timezone info to timestamps.\n",
        "  new_obj[k] = extract_dates(v)\n",
        "/home/amarin/.local/lib/python2.7/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
        ".ix is deprecated. Please use\n",
        ".loc for label based indexing or\n",
        ".iloc for positional indexing\n",
        "\n",
        "See the documentation here:\n",
        "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
        "  topic_term_dists = topic_term_dists.ix[topic_order]\n",
        "/home/amarin/.local/lib/python2.7/site-packages/pyLDAvis/_prepare.py:208: RuntimeWarning: invalid value encountered in multiply\n",
        "  relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift\n"
       ]
      },
      {
       "html": [
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
        "\n",
        "\n",
        "<div id=\"ldavis_el246141401687493228321921693004\"></div>\n",
        "<script type=\"text/javascript\">\n",
        "\n",
        "var ldavis_el246141401687493228321921693004_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 4, 3, 5], \"token.table\": {\"Topic\": [2, 2, 1, 2, 3, 1, 4, 1, 3, 1, 3, 1, 1, 1, 2, 4, 1, 2, 1, 3, 3, 3, 2, 1, 1, 1, 1, 1, 2, 2, 2, 4, 3, 4, 2, 2, 3, 3, 4, 1, 1, 1, 2, 4, 1, 4, 1, 1, 2, 2, 4, 1, 3, 4, 2, 2, 5, 4, 1, 1, 1, 2, 3, 1, 2, 3, 1, 1, 3, 1, 1, 4, 1, 1, 1, 2, 3, 2, 4, 2, 1, 1, 1, 3, 2, 3, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 3, 1, 2, 1, 4, 1, 2, 2, 4, 2, 4, 2, 1, 2, 2, 1, 3, 1, 3, 1, 2, 1, 1, 3, 1, 4, 4, 2, 4, 1, 2, 4, 4, 2, 1, 3, 1, 2, 1, 1, 2, 3, 4, 1, 1, 3, 2, 2, 1, 2, 2, 1, 1, 2, 3, 1, 1, 2, 2, 2, 1, 5, 1, 4, 3, 2, 3, 1, 3, 2, 4, 3, 1, 1, 2, 2, 4, 3, 2, 2, 1, 3, 1, 2, 3, 2, 4, 4, 1, 1, 1, 1, 2, 3, 2, 5, 1, 1, 3, 1, 3, 2, 2, 1, 2, 3, 1, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 1, 3, 1, 2, 2, 4, 2, 5, 2, 5, 1, 1, 1, 1, 3, 1, 4, 5, 1, 2, 1, 1, 3, 2], \"Freq\": [0.8084627724649267, 0.806537532485025, 1.0892907524279571, 0.7977315436218484, 0.7977315436218484, 1.3335289103237544, 0.5671158644444332, 0.46465709696399343, 0.46465709696399343, 0.490733163410119, 0.490733163410119, 0.9404513036482386, 0.9569444685694345, 0.6039858943835903, 0.3106608207045144, 0.6213216414090288, 0.7737961872292177, 1.0438899044176733, 1.1610704205115252, 1.2151475429713843, 0.5990944023086142, 1.0959529842419387, 1.0603595711991909, 0.9515507101364096, 0.950787949703266, 0.9975864501479275, 0.9283015404520586, 1.6355452994623279, 0.8956423846276522, 0.8184220312537005, 0.47766072328104286, 0.47766072328104286, 0.7076258255563113, 0.9562050786004487, 0.8653216111085721, 0.9912698311197464, 0.8462262315280655, 0.8017727533972858, 0.6168455938434158, 0.7799445189047244, 1.8457523817678603, 1.009204608887357, 0.9195533991736634, 0.7313584075942089, 1.4556937213281838, 0.8403941712787539, 1.2522573317426113, 0.9880577559299522, 1.6351337752452821, 0.7984298552091929, 1.1592558946668718, 0.5091787041289138, 0.5091787041289138, 0.8491719778848216, 1.019312151804883, 0.6999424421081992, 0.7282397191280302, 0.7640021130284989, 1.6469906724226921, 1.719703891065451, 1.3703028445887655, 1.0986512047716372, 0.9498763040351457, 0.6955935784600268, 0.4547849271035844, 0.9095698542071688, 1.6311422505155755, 0.48808528006184926, 0.48808528006184926, 1.2366739141018335, 0.807860089900648, 0.8820337452611889, 0.9275516671637419, 1.1261492752193063, 0.6958640673993501, 1.1215287015707227, 1.2924772831756521, 0.5826562837611103, 0.5826562837611103, 1.0249597993144084, 0.8181892625687582, 0.864225303210648, 0.9877271997605079, 0.6016401549180436, 0.3346492902665672, 0.3346492902665672, 0.3346492902665672, 0.9209734076251466, 1.1221801526181678, 0.6729397562933757, 0.8193673001501705, 0.6489416215306777, 1.0636086673348277, 1.2193701155378731, 1.0056319454624623, 1.179377652395392, 1.054152666639541, 0.6567384544667401, 0.9215728407420108, 0.7113964855212738, 0.8993788974139875, 0.8161220779092951, 0.8161220779092951, 0.6060601724175063, 0.7261868117549294, 1.68495636663966, 0.5406870835738856, 1.5565812506132515, 0.9625198302713301, 0.4908409313758397, 0.4908409313758397, 0.1358201546410395, 0.9507410824872764, 0.937593789358159, 0.7646410221978613, 0.9975377012198673, 0.877638501566839, 0.4756895599065607, 0.4756895599065607, 0.48457697777283093, 0.48457697777283093, 1.2717923315731585, 1.0426476551402613, 1.2672090835456422, 0.6643064508410318, 0.3321532254205159, 0.8482676174163329, 1.2861181378358457, 0.7119727134099183, 0.6262614358943671, 0.6262614358943671, 1.159465667119921, 0.7797990618198558, 0.3898995309099279, 0.7192478945297557, 0.8652330992255206, 1.762609657757999, 0.627734434739269, 0.5251381976855524, 0.5251381976855524, 0.793721721995357, 1.3795840033175302, 0.21475820685560468, 0.6442746205668141, 0.21475820685560468, 1.1126791335563837, 1.3241490054730187, 0.7640188721125333, 0.9899872674232247, 0.6782870155237666, 1.1964924615960784, 0.6706471758852467, 0.66758066213208, 0.7722741005776373, 1.5514527068056556, 0.5372655098041712, 0.5372655098041712, 0.6958094052850049, 1.4198125932469907, 1.7059167275698572, 1.028173626458241, 0.9889875308296419, 0.47359452559394993, 0.47359452559394993, 0.6965695463158806, 0.7488644855003733, 0.7593883552330158, 0.4126362678347673, 0.4126362678347673, 0.6046878235136697, 0.6046878235136697, 0.5243001512719102, 0.5243001512719102, 0.9102712444594724, 0.9264483969292411, 0.6931946571686035, 1.0582856693442597, 0.5390270424393266, 0.5390270424393266, 0.6918949936739484, 0.8270275881464056, 0.7738199540258319, 0.915426618379754, 0.7920660635167743, 1.2956678385908666, 0.486355500937284, 0.486355500937284, 0.5133634543833077, 0.5133634543833077, 0.7307939237895034, 0.9724709617480376, 0.9928846952312207, 0.8497921760760058, 0.9558455017391355, 1.2161825474918866, 0.5885126386110829, 0.24985341341874207, 0.7495602402562263, 1.2221105422165404, 0.38292781175808355, 0.38292781175808355, 0.6210696745781685, 0.6210696745781685, 0.5691959323586777, 0.769839782147179, 0.47827409026707146, 0.47827409026707146, 0.47827409026707146, 0.526365349045041, 0.526365349045041, 0.5668282792842805, 0.6668649395140137, 0.6668649395140137, 1.1890934411666172, 0.812383194312892, 0.1331062549666899, 0.7986375298001395, 0.7733520943033566, 1.1109619905550672, 0.7558519960197351, 0.486162670136187, 0.486162670136187, 1.333142582730556, 0.6915984921395351, 0.40352577128446937, 0.40352577128446937, 0.3168775448726642, 0.6337550897453283, 0.5059376477886536, 0.5059376477886536, 1.607895205684647, 1.0433361441949371, 0.7369954533276675, 0.5033127595789213, 0.5033127595789213, 0.5221328509011723, 0.5221328509011723, 0.9147949216799194, 1.383886899256992, 0.6821967888116772, 1.2596220209692155, 0.7189269139958854, 1.5203521176710102, 0.666440781598], \"Term\": [\"21st\", \"21st century\", \"abundance\", \"abuse\", \"abuse\", \"accomplished\", \"account\", \"activity\", \"activity\", \"addition\", \"addition\", \"adequate\", \"adjustment\", \"affair\", \"afghanistan\", \"afghanistan\", \"aggression\", \"agree\", \"agriculture\", \"alaska\", \"amendment\", \"anti\", \"applause\", \"appropriation\", \"atlantic\", \"atomic\", \"atomic energy\", \"authorized\", \"big\", \"bipartisan\", \"border\", \"border\", \"capability\", \"character\", \"child care\", \"class\", \"closely\", \"coal\", \"coalition\", \"collective\", \"command\", \"communist\", \"company\", \"compassion\", \"concept\", \"confront\", \"constitutional\", \"contribution\", \"cover\", \"create job\", \"culture\", \"current\", \"current\", \"death\", \"democrat\", \"democrat republican\", \"desire\", \"destruction\", \"detailed\", \"deterrent\", \"dispute\", \"easier\", \"economic development\", \"effectively\", \"environmental\", \"environmental\", \"equality\", \"established\", \"established\", \"estimate\", \"european\", \"evil\", \"expenditure\", \"extension\", \"facility\", \"father\", \"federal program\", \"fellow citizen\", \"fellow citizen\", \"finish\", \"fiscal year\", \"free nation\", \"free world\", \"fuel\", \"funding\", \"funding\", \"funding\", \"global\", \"global economy\", \"god bless\", \"got\", \"governor\", \"graduate\", \"gun\", \"harder\", \"head\", \"hero\", \"high school\", \"hire\", \"human right\", \"immigrant\", \"indian\", \"indian\", \"industrial\", \"innovation\", \"insure\", \"intelligence\", \"internal\", \"invest\", \"iran\", \"iran\", \"iraq\", \"iraq\", \"kid\", \"labor management\", \"laughter\", \"leading\", \"legislative\", \"legislative\", \"local government\", \"local government\", \"long range\", \"lot\", \"maintenance\", \"management\", \"management\", \"mankind\", \"marine\", \"mass\", \"math\", \"math\", \"medical care\", \"medicare\", \"medicare\", \"medicine\", \"middle class\", \"military power\", \"minority\", \"missile\", \"missile\", \"mutual\", \"nature\", \"oil\", \"oil\", \"oil\", \"old age\", \"output\", \"passage\", \"passing\", \"paying\", \"peacetime\", \"police\", \"politics\", \"population\", \"private enterprise\", \"private sector\", \"private sector\", \"productive\", \"proper\", \"public school\", \"read\", \"rebuild\", \"recommend\", \"recommend\", \"recommended\", \"regime\", \"regional\", \"regulation\", \"regulation\", \"relationship\", \"relationship\", \"relief\", \"relief\", \"reorganization\", \"representative\", \"republic\", \"republican\", \"retirement\", \"retirement\", \"review\", \"reward\", \"right thing\", \"river\", \"rural\", \"satellite\", \"sector\", \"sector\", \"senior\", \"senior\", \"september\", \"session\", \"shall\", \"shall continue\", \"shortage\", \"sick\", \"significant\", \"south\", \"south\", \"standard living\", \"state local\", \"state local\", \"state local government\", \"state local government\", \"stay\", \"story\", \"strategic\", \"strategic\", \"strategic\", \"surplus\", \"surplus\", \"tax cut\", \"tax relief\", \"tax relief\", \"teach\", \"terror\", \"terrorist\", \"terrorist\", \"told\", \"tomorrow\", \"tough\", \"transportation\", \"transportation\", \"tremendous\", \"trillion\", \"troop\", \"troop\", \"try\", \"try\", \"trying\", \"trying\", \"ultimate\", \"understanding\", \"united nation\", \"urban\", \"urban\", \"victory\", \"victory\", \"vietnam\", \"western europe\", \"working family\", \"world peace\", \"world war\", \"year administration\", \"yes\"]}, \"mdsDat\": {\"y\": [-0.1655643761041196, 0.058157070315217364, -0.19406463567298105, 0.36620498463032053, -0.06473304316843677], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [40.18754894296077, 36.78269762153606, 13.283561338311248, 7.038428059213285, 2.707764037978627], \"topics\": [1, 2, 3, 4, 5], \"x\": [-0.1203856078288832, -0.14129066632482837, -0.15532204707685832, -0.034490952354003325, 0.4514892735845732]}, \"R\": 30, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Term\": [\"vietnam\", \"iraq\", \"terrorist\", \"south\", \"recommend\", \"try\", \"terror\", \"communist\", \"regime\", \"shall\", \"trying\", \"afghanistan\", \"aggression\", \"oil\", \"troop\", \"stay\", \"coalition\", \"victory\", \"desire\", \"funding\", \"border\", \"account\", \"relief\", \"environmental\", \"expenditure\", \"master\", \"intelligence\", \"regional\", \"tax relief\", \"company\", \"atomic\", \"insure\", \"free world\", \"western europe\", \"session\", \"military power\", \"concept\", \"atlantic\", \"peacetime\", \"adjustment\", \"internal\", \"carried\", \"detailed\", \"private enterprise\", \"authorized\", \"nature\", \"various\", \"collective\", \"output\", \"deterrent\", \"ultimate\", \"satellite\", \"mankind\", \"equality\", \"appropriation\", \"proper\", \"businessmen\", \"considered\", \"accomplished\", \"command\", \"shall\", \"free nation\", \"republic\", \"labor management\", \"shall continue\", \"atomic energy\", \"shortage\", \"understanding\", \"old age\", \"extension\", \"medical care\", \"standard living\", \"world peace\", \"long range\", \"tremendous\", \"dispute\", \"expenditure\", \"maintenance\", \"communist\", \"adequate\", \"agriculture\", \"european\", \"mutual\", \"productive\", \"aggression\", \"united nation\", \"fiscal year\", \"affair\", \"industrial\", \"population\", \"world war\", \"facility\", \"management\", \"recommend\", \"recommended\", \"activity\", \"surplus\", \"missile\", \"21st\", \"easier\", \"graduate\", \"got\", \"god bless\", \"global economy\", \"story\", \"finish\", \"father\", \"teach\", \"big\", \"told\", \"democrat republican\", \"democrat\", \"trillion\", \"cover\", \"company\", \"class\", \"gun\", \"sick\", \"harder\", \"hero\", \"paying\", \"passing\", \"public school\", \"read\", \"middle class\", \"lot\", \"laughter\", \"republican\", \"kid\", \"21st century\", \"invest\", \"agree\", \"applause\", \"politics\", \"working family\", \"right thing\", \"create job\", \"reward\", \"child care\", \"immigrant\", \"hire\", \"tough\", \"bipartisan\", \"yes\", \"global\", \"medicare\", \"high school\", \"tomorrow\", \"innovation\", \"tax cut\", \"governor\", \"troop\", \"year administration\", \"reorganization\", \"minority\", \"community development\", \"coal\", \"alaska\", \"consultation\", \"environmental\", \"human right\", \"continue work\", \"assistance program\", \"significant\", \"dependence\", \"passage\", \"review\", \"respond\", \"judicial\", \"federal program\", \"mental\", \"economic development\", \"automobile\", \"rural\", \"executive order\", \"capability\", \"closely\", \"technological\", \"oil\", \"overall\", \"anti\", \"administrative\", \"state local government\", \"fuel\", \"regulation\", \"urban\", \"addition\", \"local government\", \"legislative\", \"indian\", \"established\", \"abuse\", \"state local\", \"amendment\", \"transportation\", \"sector\", \"funding\", \"management\", \"strategic\", \"private sector\", \"current\", \"relationship\", \"regime\", \"iraq\", \"terror\", \"terrorist\", \"september\", \"coalition\", \"evil\", \"compassion\", \"culture\", \"marine\", \"tax relief\", \"medicine\", \"character\", \"confront\", \"mass\", \"option\", \"account\", \"afghanistan\", \"intelligence\", \"friend ally\", \"destruction\", \"death\", \"temporary\", \"deny\", \"tyranny\", \"relief\", \"territory\", \"grateful\", \"intention\", \"shown\", \"fellow citizen\", \"border\", \"troop\", \"iran\", \"retirement\", \"senior\", \"leading\", \"funding\", \"victory\", \"math\", \"oil\", \"vietnam\", \"south\", \"try\", \"association\", \"trying\", \"modernize\", \"desire\", \"recommend\", \"master\", \"pursuit\", \"rebuild\", \"tried\", \"wish\", \"estimate\", \"limited\", \"regional\", \"battle\", \"representative\", \"stay\", \"abundance\", \"effectively\", \"contribution\", \"victory\", \"river\", \"aggression\", \"recommended\", \"head\", \"constitutional\", \"police\", \"adversary\", \"communist\", \"local government\", \"state local\"], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9112, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.9116, 0.8865, 0.9099, 0.8195, 0.8292, 0.8386, 0.8672, 0.8604, 0.8433, 0.7566, 0.74, 0.7422, 0.7938, 0.7943, 0.8338, 0.7985, 0.7695, 0.4849, 0.2916, 0.7603, 0.5451, 0.5869, 0.53, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 0.9976, 0.9625, 0.9586, 0.8754, 0.7728, 0.9342, 0.8408, 0.9693, 0.8173, 0.8908, 0.4713, 1.8479, 1.8261, 1.7943, 1.7709, 1.7641, 1.7518, 1.7515, 1.7512, 1.7304, 1.7255, 1.7051, 1.6861, 1.6674, 1.6651, 1.6626, 1.6434, 1.6407, 1.6306, 1.6296, 1.6259, 1.6148, 1.5747, 1.5716, 1.5714, 1.5694, 1.5555, 1.544, 1.5302, 1.5206, 1.52, 1.5132, 1.4998, 1.4711, 1.4755, 1.4713, 1.4479, 1.3863, 1.482, 1.3588, 1.4734, 1.2747, 1.3223, 1.2387, 1.2248, 1.0502, 0.9612, 1.1661, 1.1915, 1.1281, 1.2116, 2.552, 2.5344, 2.5212, 2.4566, 2.4563, 2.3995, 2.36, 2.3114, 2.2876, 2.2331, 2.2175, 2.2057, 2.1795, 2.1452, 2.1321, 2.13, 2.1268, 2.1067, 2.0992, 2.0833, 2.0523, 1.9998, 1.9821, 1.9787, 1.9466, 1.9454, 1.8997, 1.8865, 1.8731, 1.8725, 1.8582, 1.8155, 1.7639, 1.7789, 1.7646, 1.6871, 1.8294, 1.3379, 1.4881, 1.5999, 0.5077, 3.5378, 3.2362, 3.1675, 2.9689, 2.9522, 2.8909, 2.7924, 2.7621, 2.7502, 2.7253, 2.6752, 2.5904, 2.58, 2.5591, 2.4756, 2.4519, 2.3252, 2.1691, 2.0261, 2.0253, 1.9001, 1.8832, 1.85, 1.7155, 1.6681, 1.641, 1.4226, 1.4161, 1.2016, 1.1996, 1.1789, 0.922, 0.6156], \"Freq\": [12.0, 7.0, 7.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 7.0, 1.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.004838778336884, 0.5934871785400109, 3.0372758801493, 0.7226024038069148, 2.0566166792322074, 0.5673405882003268, 0.6869576926440226, 1.0517592280298595, 0.8357762644538818, 1.044992716761225, 0.6424335379897623, 0.384139273449718, 0.6071679802102454, 0.6445571918585502, 0.6114168774956841, 0.7248561867891101, 0.4428087113757455, 1.2821424803450114, 0.7552020171950174, 0.5814954569768666, 0.6219310788815972, 0.7718027492968977, 1.1788732464476435, 0.6130673150572352, 1.0509161407242762, 0.7043183056385526, 0.49931657169771737, 0.4671033322360424, 0.7498900040773918, 0.5417844830530305, 7.050164065999483, 2.3142113434655083, 1.4425962313162681, 1.3078032318036374, 1.1767583041510135, 1.0772361742640502, 1.0461941790598235, 0.9580788285765913, 0.8987316916816489, 0.8879817462966977, 0.8624662448901751, 0.8182565860092339, 0.7938889471228445, 0.7862918930821341, 0.7501073125665148, 0.7297656893503018, 3.1540596640694574, 0.7877805909193314, 3.6146223068315555, 1.958379332735111, 1.6012717694436838, 1.1840671324119714, 1.1970186187384648, 1.3422856416276214, 2.2135699494444196, 2.2858762143710583, 2.0635741980076965, 1.4715921472514926, 1.4672953179270078, 1.1978920948075475, 1.2422319364560441, 1.2466646215180823, 1.9649204638032989, 2.2717119803442114, 1.2340420846055689, 1.4917588054637438, 1.3730576533213796, 1.3001452235181983, 2.4738306674309674, 0.9102069843976164, 0.9401954221619712, 2.440907758502747, 1.4860171221092766, 0.8911225151032048, 1.2989715823867605, 0.9756480211896077, 0.8916401324366292, 0.8409768024781148, 2.2330341153198834, 1.2930720785088325, 1.428688903316163, 1.962107482441591, 1.4459256510325686, 0.611570756557819, 3.2624532764447225, 3.0264211678985284, 1.6401910908877617, 0.8222449845726563, 0.994399595709072, 0.948629199210613, 1.474302142180637, 1.0101140013677516, 0.586195084343031, 0.9725983766425803, 2.3115158236436186, 1.9181935432741677, 3.0074051299829216, 2.834773338524819, 3.1996798976811545, 2.4797358082491145, 2.0778792676263187, 1.9159108556717828, 1.8861526356933271, 1.497946325776212, 1.46585269294789, 1.2922902734640747, 1.2524581758506446, 1.2091495064164337, 1.1556396918353744, 1.1118784339674097, 1.0851014220371804, 1.3195958149978053, 2.353332879145232, 1.4394162780194941, 1.9169416415331428, 2.0431684408650255, 1.4255322866716411, 1.5350693203474743, 1.335238914668788, 1.4693617724081665, 1.3814123944173888, 1.4603440340776972, 0.5545256328812573, 0.9062022816990041, 1.2729251486163216, 0.4281105728005081, 0.9669887507114733, 0.6302351605644363, 0.34500461546082534, 1.68285553408062, 1.0536490643782372, 0.4401960452853558, 0.4969513361259454, 1.2184920773480572, 0.403740693893912, 0.9190682236897025, 1.0123501341901, 0.43929711216043404, 0.3552997931574471, 0.5248531871423474, 0.3926694165948775, 0.7108230953854302, 0.3480655728461863, 1.6197467031517647, 0.3372766636195571, 0.9035419674613722, 0.7540792011715661, 0.414350299006128, 2.8967940436860515, 0.42324577100874866, 0.5545302849278034, 0.3194853477867757, 0.9713157799100317, 0.9893506043493272, 1.4015770533759953, 1.1542205941050676, 1.1788749456024339, 1.1661669783523896, 1.1170288209795982, 0.7164447807974152, 1.0591545453004052, 0.7267083908454631, 1.2410387283469808, 0.8319615415178051, 0.9429809020229056, 0.9295424787555333, 1.1345813085570697, 1.0457382426836548, 0.8913943952281547, 0.8138953805340493, 0.8060443168869909, 0.7378525328909495, 2.412340157365495, 6.534443636232458, 3.2341333039391893, 6.168580052749391, 1.1231954968450308, 1.2571125266401613, 0.8451387209517, 0.9709453242726385, 0.5981290968322535, 0.5105429720647122, 0.969337789232609, 0.8882638970351414, 0.6508172142414317, 0.7155815077017862, 0.833616301377089, 0.4734582882347867, 1.0410353542714197, 1.8625497906259652, 1.0622156857102276, 0.3590518833093251, 0.7172963917192825, 0.6123232426750436, 0.4771459472260875, 0.4106765696871425, 0.42583097411418086, 0.9392685133971961, 0.23400721314117987, 0.3861443554807773, 0.2956901355023723, 0.23865620297116738, 0.7746216814300584, 0.905353441820622, 1.0178124336415366, 0.8493495672668464, 0.7624429176458162, 0.7408644170688411, 0.49964061177673014, 0.801519317321179, 0.5970018298361438, 0.5566333079185686, 0.544541188268181, 11.197373909488185, 2.7567228757822413, 2.029340167728784, 0.3549088391543003, 1.0248025976312614, 0.2917745037862565, 0.6067937510858221, 1.8104704366424857, 0.4779642514017058, 0.37180729148743147, 0.39741523022297187, 0.35107224546152055, 0.37028146669940837, 0.28297913262857277, 0.31752803710222405, 0.41397527679866813, 0.31979567809877607, 0.25575551323806317, 0.3607901650511941, 0.18839086522591358, 0.2602945204140246, 0.18016616047888925, 0.3298052319390059, 0.16444524097388322, 0.37108998169523855, 0.20058684239819735, 0.09523089193255539, 0.08911264271820754, 0.13426476571930757, 0.06442087685944717, 0.3488950659338941, 0.14049344808040054, 0.13086798904293612], \"Total\": [12.0, 7.0, 7.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 7.0, 1.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.004838778336884, 0.5934871785400109, 3.0372758801493, 0.7226024038069148, 2.0566166792322074, 0.5673405882003268, 0.6869576926440226, 1.0517592280298595, 0.8357762644538818, 1.044992716761225, 0.6424335379897623, 0.384139273449718, 0.6071679802102454, 0.6445571918585502, 0.6114168774956841, 0.7248561867891101, 0.4428087113757455, 1.2821424803450114, 0.7552020171950174, 0.5814954569768666, 0.6219310788815972, 0.7718027492968977, 1.1788732464476435, 0.6130673150572352, 1.0509161407242762, 0.7043183056385526, 0.49931657169771737, 0.4671033322360424, 0.7498900040773918, 0.5417844830530305, 7.050164065999483, 2.3142113434655083, 1.4425962313162681, 1.3078032318036374, 1.1767583041510135, 1.0772361742640502, 1.0461941790598235, 0.9584638714607397, 0.8987316916816489, 0.8879817462966977, 0.8624662448901751, 0.8182565860092339, 0.7938889471228445, 0.7862918930821341, 0.7501073125665148, 0.7297656893503018, 3.234321177140859, 0.789135757456857, 3.9635173727654496, 2.126638553470568, 1.722548404186262, 1.2378381015492197, 1.2598874042228236, 1.4371751695284976, 2.584659931139658, 2.713720947625442, 2.4444222033920004, 1.6556678049916542, 1.6500011805941837, 1.294877038155275, 1.3909619747602373, 1.4370622753051407, 3.0106587064869537, 4.2230217874493725, 1.435606832496406, 2.15212466684328, 1.8998211067925563, 1.9042606392132804, 2.4738306674309674, 0.9102069843976164, 0.9401954221619712, 2.440907758502747, 1.4860171221092766, 0.8911225151032048, 1.2989715823867605, 0.9756480211896077, 0.8916401324366292, 0.8409768024781148, 2.2330341153198834, 1.2930720785088325, 1.428688903316163, 1.962107482441591, 1.4459256510325686, 0.611570756557819, 3.2624532764447225, 3.0264211678985284, 1.6401910908877617, 0.8222449845726563, 0.994399595709072, 0.948629199210613, 1.474302142180637, 1.0101140013677516, 0.586195084343031, 0.9725983766425803, 2.3115158236436186, 1.9181935432741677, 3.0074051299829216, 2.834773338524819, 3.1996798976811545, 2.4797358082491145, 2.0778792676263187, 1.9159108556717828, 1.8861526356933271, 1.497946325776212, 1.46585269294789, 1.2922902734640747, 1.2524581758506446, 1.2091495064164337, 1.1556396918353744, 1.1118784339674097, 1.0851014220371804, 1.3230103317394564, 2.4437269814649274, 1.5005084136690847, 2.171615362008408, 2.5647632805975693, 1.5226761783151288, 1.800241607726602, 1.3770561291017718, 1.7642027339614643, 1.5409706618004722, 2.478156467719234, 0.6577423666379834, 1.0985736461375415, 1.5930303399961678, 0.5484697040361662, 1.2472361972426502, 0.8229453334981143, 0.45064427766939086, 2.1988415631291014, 1.4056858873392561, 0.5901562814453469, 0.6799940250340458, 1.6991988521436792, 0.5736420683282972, 1.308868192267257, 1.445306020628969, 0.6393534581563846, 0.5184993860026691, 0.773707989314112, 0.5794371246260701, 1.052768656036502, 0.5212609557979581, 2.5250419025907984, 0.5273904248455922, 1.4131762350728707, 1.1817170902327843, 0.6584242139940987, 4.65639946729655, 0.6897866269300708, 0.9124479009395567, 0.5260041932689163, 1.6101253062777563, 1.6621231010357373, 2.423441849276399, 1.9868361788336428, 2.037767313403013, 2.063655612769946, 2.102211367002524, 1.2253068836977858, 2.048822287517628, 1.2535545422458982, 2.6114582678360136, 1.669186018341172, 2.0569246909061807, 2.0561091589852314, 2.988202960787525, 3.0106587064869537, 2.0908512929094556, 1.8612771185786552, 1.9639470227074152, 1.6537458852557725, 2.670710173501749, 7.3626775248703735, 3.69283857790458, 7.51279494904467, 1.368374814632474, 1.6211512410573312, 1.1337434711229544, 1.3673186629377558, 0.8626223119506877, 0.7775335488874315, 1.4995540187324328, 1.3903412267251753, 1.0458007621792302, 1.1899178197278402, 1.4045482097349002, 0.7994007269557417, 1.7633081045610237, 3.218944692582113, 1.8494985924022886, 0.6351909400854487, 1.30889690348631, 1.1776177571130781, 0.934028219168157, 0.8066382410075724, 0.8637123982045204, 1.9073044277673392, 0.4974239678142752, 0.8316876128335076, 0.6454968355889897, 0.5213016835272966, 1.716277723025469, 2.0935361675354383, 2.478156467719234, 2.0373199056504405, 1.8551944916799994, 1.9479376481936725, 1.1394212972820932, 2.988202960787525, 1.9152213814435453, 1.596777228621614, 4.65639946729655, 12.024552978278148, 4.002346761315, 3.155793195765404, 0.6731793201050444, 1.9765281440722753, 0.5983123878812582, 1.3731742086209833, 4.2230217874493725, 1.1282249166050058, 0.8997498458662387, 1.0111350940502961, 0.9722689349099567, 1.0361444088425302, 0.8086205980387934, 0.9864005897832535, 1.3168492683735626, 1.1546775418871391, 1.079390933498886, 1.75686427669313, 0.9180285408382161, 1.4376210922100487, 1.0120865850183098, 1.9152213814435453, 1.092386849936629, 2.584659931139658, 1.435606832496406, 0.8479048233353714, 0.7985579119017207, 1.491097011897517, 0.716877537906315, 3.9635173727654496, 2.063655612769946, 2.6114582678360136], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.3154, -6.5327, -4.9, -6.3359, -5.2899, -6.5778, -6.3865, -5.9605, -6.1904, -5.967, -6.4535, -6.9678, -6.5099, -6.4502, -6.503, -6.3328, -6.8256, -5.7625, -6.2918, -6.5532, -6.4859, -6.27, -5.8464, -6.5003, -5.9613, -6.3615, -6.7055, -6.7722, -6.2988, -6.6239, -4.0579, -5.1719, -5.6446, -5.7427, -5.8482, -5.9366, -5.9658, -6.0538, -6.1178, -6.1298, -6.159, -6.2116, -6.2418, -6.2514, -6.2985, -6.326, -4.8623, -6.2495, -4.726, -5.3389, -5.5402, -5.842, -5.8312, -5.7166, -5.2164, -5.1843, -5.2866, -5.6247, -5.6276, -5.8304, -5.7941, -5.7905, -5.3355, -5.1905, -5.8007, -5.611, -5.694, -5.7485, -5.0167, -6.0166, -5.9841, -5.0301, -5.5264, -6.0377, -5.6609, -5.9471, -6.0372, -6.0957, -5.1191, -5.6654, -5.5657, -5.2485, -5.5537, -6.4142, -4.74, -4.8151, -5.4277, -6.1182, -5.9281, -5.9752, -5.5343, -5.9124, -6.4566, -5.9503, -5.0846, -5.2711, -4.8214, -4.8805, -4.7594, -5.0143, -5.1911, -5.2723, -5.2879, -5.5184, -5.54, -5.6661, -5.6974, -5.7326, -5.7778, -5.8164, -5.8408, -5.6451, -5.0666, -5.5582, -5.2717, -5.208, -5.5679, -5.4939, -5.6334, -5.5376, -5.5994, -5.5438, -5.4936, -5.0025, -4.6627, -5.7523, -4.9375, -5.3656, -5.9682, -4.3835, -4.8517, -5.7245, -5.6032, -4.7064, -5.811, -4.9884, -4.8917, -5.7265, -5.9388, -5.5486, -5.8388, -5.2453, -5.9593, -4.4217, -5.9908, -5.0054, -5.1862, -5.785, -3.8404, -5.7638, -5.4936, -6.045, -4.9331, -4.9147, -4.5664, -4.7605, -4.7394, -4.7502, -4.7933, -5.2374, -4.8465, -5.2232, -4.688, -5.0879, -4.9627, -4.977, -4.7777, -4.8592, -5.0189, -5.1099, -5.1196, -5.208, -3.3882, -2.3917, -3.0951, -2.4494, -4.1526, -4.04, -4.4371, -4.2983, -4.7828, -4.9411, -4.3, -4.3873, -4.6984, -4.6035, -4.4508, -5.0165, -4.2286, -3.6469, -4.2085, -5.2931, -4.6011, -4.7593, -5.0088, -5.1588, -5.1225, -4.3315, -5.7212, -5.2204, -5.4873, -5.7016, -4.5242, -4.3683, -4.2512, -4.4321, -4.5401, -4.5688, -4.9627, -4.4901, -4.7847, -4.8547, -4.8766, -0.8979, -2.2995, -2.6059, -4.3495, -3.2891, -4.5453, -3.8131, -2.72, -4.0518, -4.3029, -4.2363, -4.3603, -4.3071, -4.5759, -4.4608, -4.1955, -4.4536, -4.6771, -4.333, -4.9828, -4.6595, -5.0274, -4.4228, -5.1187, -4.3049, -4.9201, -5.665, -5.7314, -5.3215, -6.0559, -4.3666, -5.2762, -5.3471]}};\n",
        "\n",
        "function LDAvis_load_lib(url, callback){\n",
        "  var s = document.createElement('script');\n",
        "  s.src = url;\n",
        "  s.async = true;\n",
        "  s.onreadystatechange = s.onload = callback;\n",
        "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
        "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
        "}\n",
        "\n",
        "if(typeof(LDAvis) !== \"undefined\"){\n",
        "   // already loaded: just create the visualization\n",
        "   !function(LDAvis){\n",
        "       new LDAvis(\"#\" + \"ldavis_el246141401687493228321921693004\", ldavis_el246141401687493228321921693004_data);\n",
        "   }(LDAvis);\n",
        "}else if(typeof define === \"function\" && define.amd){\n",
        "   // require.js is available: use it to load d3/LDAvis\n",
        "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
        "   require([\"d3\"], function(d3){\n",
        "      window.d3 = d3;\n",
        "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
        "        new LDAvis(\"#\" + \"ldavis_el246141401687493228321921693004\", ldavis_el246141401687493228321921693004_data);\n",
        "      });\n",
        "    });\n",
        "}else{\n",
        "    // require.js not available: dynamically load d3 & LDAvis\n",
        "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
        "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
        "                 new LDAvis(\"#\" + \"ldavis_el246141401687493228321921693004\", ldavis_el246141401687493228321921693004_data);\n",
        "            })\n",
        "         });\n",
        "}\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
        "topic                                                \n",
        "0      40.187549        1       1 -0.120386 -0.165564\n",
        "1      36.782698        1       2 -0.141291  0.058157\n",
        "3      13.283561        1       3 -0.155322 -0.194065\n",
        "2       7.038428        1       4 -0.034491  0.366205\n",
        "4       2.707764        1       5  0.451489 -0.064733, topic_info=     Category       Freq              Term      Total  loglift  logprob\n",
        "term                                                                   \n",
        "947   Default  12.000000           vietnam  12.000000  30.0000  30.0000\n",
        "476   Default   7.000000              iraq   7.000000  29.0000  29.0000\n",
        "879   Default   7.000000         terrorist   7.000000  28.0000  28.0000\n",
        "813   Default   4.000000             south   4.000000  27.0000  27.0000\n",
        "717   Default   4.000000         recommend   4.000000  26.0000  26.0000\n",
        "913   Default   3.000000               try   3.000000  25.0000  25.0000\n",
        "878   Default   3.000000            terror   3.000000  24.0000  24.0000\n",
        "152   Default   3.000000         communist   3.000000  23.0000  23.0000\n",
        "723   Default   2.000000            regime   2.000000  22.0000  22.0000\n",
        "787   Default   7.000000             shall   7.000000  21.0000  21.0000\n",
        "914   Default   1.000000            trying   1.000000  20.0000  20.0000\n",
        "34    Default   3.000000       afghanistan   3.000000  19.0000  19.0000\n",
        "36    Default   2.000000        aggression   2.000000  18.0000  18.0000\n",
        "604   Default   4.000000               oil   4.000000  17.0000  17.0000\n",
        "908   Default   2.000000             troop   2.000000  16.0000  16.0000\n",
        "829   Default   1.000000              stay   1.000000  15.0000  15.0000\n",
        "138   Default   1.000000         coalition   1.000000  14.0000  14.0000\n",
        "946   Default   1.000000           victory   1.000000  13.0000  13.0000\n",
        "236   Default   1.000000            desire   1.000000  12.0000  12.0000\n",
        "384   Default   2.000000           funding   2.000000  11.0000  11.0000\n",
        "99    Default   2.000000            border   2.000000  10.0000  10.0000\n",
        "9     Default   1.000000           account   1.000000   9.0000   9.0000\n",
        "728   Default   1.000000            relief   1.000000   8.0000   8.0000\n",
        "308   Default   2.000000     environmental   2.000000   7.0000   7.0000\n",
        "329   Default   3.000000       expenditure   3.000000   6.0000   6.0000\n",
        "542   Default   1.000000            master   1.000000   5.0000   5.0000\n",
        "467   Default   1.000000      intelligence   1.000000   4.0000   4.0000\n",
        "724   Default   1.000000          regional   1.000000   3.0000   3.0000\n",
        "871   Default   1.000000        tax relief   1.000000   2.0000   2.0000\n",
        "154   Default   3.000000           company   3.000000   1.0000   1.0000\n",
        "...       ...        ...               ...        ...      ...      ...\n",
        "70     Topic5   0.354909       association   0.673179   2.9689  -4.3495\n",
        "914    Topic5   1.024803            trying   1.976528   2.9522  -3.2891\n",
        "570    Topic5   0.291775         modernize   0.598312   2.8909  -4.5453\n",
        "236    Topic5   0.606794            desire   1.373174   2.7924  -3.8131\n",
        "717    Topic5   1.810470         recommend   4.223022   2.7621  -2.7200\n",
        "542    Topic5   0.477964            master   1.128225   2.7502  -4.0518\n",
        "694    Topic5   0.371807           pursuit   0.899750   2.7253  -4.3029\n",
        "710    Topic5   0.397415           rebuild   1.011135   2.6752  -4.2363\n",
        "906    Topic5   0.351072             tried   0.972269   2.5904  -4.3603\n",
        "979    Topic5   0.370281              wish   1.036144   2.5800  -4.3071\n",
        "316    Topic5   0.282979          estimate   0.808621   2.5591  -4.5759\n",
        "520    Topic5   0.317528           limited   0.986401   2.4756  -4.4608\n",
        "724    Topic5   0.413975          regional   1.316849   2.4519  -4.1955\n",
        "89     Topic5   0.319796            battle   1.154678   2.3252  -4.4536\n",
        "738    Topic5   0.255756    representative   1.079391   2.1691  -4.6771\n",
        "829    Topic5   0.360790              stay   1.756864   2.0261  -4.3330\n",
        "2      Topic5   0.188391         abundance   0.918029   2.0253  -4.9828\n",
        "280    Topic5   0.260295       effectively   1.437621   1.9001  -4.6595\n",
        "188    Topic5   0.180166      contribution   1.012087   1.8832  -5.0274\n",
        "946    Topic5   0.329805           victory   1.915221   1.8500  -4.4228\n",
        "757    Topic5   0.164445             river   1.092387   1.7155  -5.1187\n",
        "36     Topic5   0.371090        aggression   2.584660   1.6681  -4.3049\n",
        "718    Topic5   0.200587       recommended   1.435607   1.6410  -4.9201\n",
        "414    Topic5   0.095231              head   0.847905   1.4226  -5.6650\n",
        "179    Topic5   0.089113    constitutional   0.798558   1.4161  -5.7314\n",
        "649    Topic5   0.134265            police   1.491097   1.2016  -5.3215\n",
        "30     Topic5   0.064421         adversary   0.716878   1.1996  -6.0559\n",
        "152    Topic5   0.348895         communist   3.963517   1.1789  -4.3666\n",
        "521    Topic5   0.140493  local government   2.063656   0.9220  -5.2762\n",
        "826    Topic5   0.130868       state local   2.611458   0.6156  -5.3471\n",
        "\n",
        "[276 rows x 6 columns], token_table=      Topic      Freq                 Term\n",
        "term                                      \n",
        "0         2  0.808463                 21st\n",
        "1         2  0.806538         21st century\n",
        "2         1  1.089291            abundance\n",
        "3         2  0.797732                abuse\n",
        "3         3  0.797732                abuse\n",
        "7         1  1.333529         accomplished\n",
        "9         4  0.567116              account\n",
        "16        1  0.464657             activity\n",
        "16        3  0.464657             activity\n",
        "20        1  0.490733             addition\n",
        "20        3  0.490733             addition\n",
        "22        1  0.940451             adequate\n",
        "23        1  0.956944           adjustment\n",
        "31        1  0.603986               affair\n",
        "34        2  0.310661          afghanistan\n",
        "34        4  0.621322          afghanistan\n",
        "36        1  0.773796           aggression\n",
        "38        2  1.043890                agree\n",
        "41        1  1.161070          agriculture\n",
        "44        3  1.215148               alaska\n",
        "49        3  0.599094            amendment\n",
        "54        3  1.095953                 anti\n",
        "55        2  1.060360             applause\n",
        "58        1  0.951551        appropriation\n",
        "72        1  0.950788             atlantic\n",
        "73        1  0.997586               atomic\n",
        "74        1  0.928302        atomic energy\n",
        "78        1  1.635545           authorized\n",
        "92        2  0.895642                  big\n",
        "94        2  0.818422           bipartisan\n",
        "...     ...       ...                  ...\n",
        "878       4  0.812383               terror\n",
        "879       2  0.133106            terrorist\n",
        "879       4  0.798638            terrorist\n",
        "887       2  0.773352                 told\n",
        "888       2  1.110962             tomorrow\n",
        "892       2  0.755852                tough\n",
        "900       1  0.486163       transportation\n",
        "900       3  0.486163       transportation\n",
        "904       1  1.333143           tremendous\n",
        "907       2  0.691598             trillion\n",
        "908       2  0.403526                troop\n",
        "908       4  0.403526                troop\n",
        "913       2  0.316878                  try\n",
        "913       5  0.633755                  try\n",
        "914       2  0.505938               trying\n",
        "914       5  0.505938               trying\n",
        "920       1  1.607895             ultimate\n",
        "923       1  1.043336        understanding\n",
        "931       1  0.736995        united nation\n",
        "937       1  0.503313                urban\n",
        "937       3  0.503313                urban\n",
        "946       1  0.522133              victory\n",
        "946       4  0.522133              victory\n",
        "947       5  0.914795              vietnam\n",
        "972       1  1.383887       western europe\n",
        "980       2  0.682197       working family\n",
        "982       1  1.259622          world peace\n",
        "984       1  0.718927            world war\n",
        "991       3  1.520352  year administration\n",
        "997       2  0.666441                  yes\n",
        "\n",
        "[244 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 4, 3, 5])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The LDA model allows 1- to 3-word phrases to be considered as terms\n",
      "### Only allow terms that appear in more than 5% and less than 60% of the speeches, as the idea is to find the terms that distinguish one speech from another.\n",
      "\n",
      "\n",
      "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
      "\n",
      "(soviet union)\n",
      "vietnam\n",
      "space\n",
      "waste\n",
      "modern\n",
      "missile\n",
      "strategic\n",
      "secretary\n",
      "revolution\n",
      "recovery\n",
      "\n",
      "shall \n",
      "expenditure\n",
      "(fiscal year)\n",
      "(million dollar)\n",
      "recommendation\n",
      "recommended\n",
      "(united nation)\n",
      "period\n",
      "(management employment)\n",
      "surplus\n",
      "\n",
      "college\n",
      "parent\n",
      "republican\n",
      "(21st century)\n",
      "(small business)\n",
      "tell\n",
      "kids\n",
      "global\n",
      "medicare\n",
      "\n",
      "terrorist\n",
      "enemy\n",
      "iraq\n",
      "oil\n",
      "(troop border)\n",
      "(america will)\n",
      "afganistan\n",
      "terror\n",
      "violence\n",
      "asked\n",
      "debate\n",
      "retirement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![alt text](https://cdn-images-1.medium.com/max/1600/1*MLJVWz4EdOFsqhvBxEi9iA.png \"Topic Analysis\")\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''docs_num = float(len(documents))\n",
      "print(\"Length tfidf features before removing high and low presence: %i \" %len(tfidf_feature_names))\n",
      "print(\"Length tf features before removing high and low presence: %i \" %len(tf_feature_names))\n",
      "\n",
      "def remove_presence(features, documents, min_presence = 0.05, max_presence = 0.95):\n",
      "    docs_num = float(len(documents))\n",
      "    for term in features:\n",
      "        c = 0\n",
      "        for doc in documents:\n",
      "            c += int(term in doc)\n",
      "        if (c > docs_num * max_presence) or (c < min_presence):\n",
      "            features.remove(term)\n",
      "    return features\n",
      "\n",
      "tfidf_feature_names = remove_presence(tfidf_feature_names, documents, min_presence = 0.05, max_presence = 0.6)\n",
      "print(\"Length tfidf features after removing high and low presence: %i \" % len(tfidf_feature_names))\n",
      "tf_feature_names = remove_presence(tf_feature_names, documents, min_presence = 0.05, max_presence = 0.6)\n",
      "print(\"Length tf features after removing high and low presence: %i \" % len(tf_feature_names))\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-08-04 15:56:13.157065. Please add timezone info to timestamps.\n",
        "  new_obj[k] = extract_dates(v)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "'docs_num = float(len(documents))\\nprint(\"Length tfidf features before removing high and low presence: %i \" %len(tfidf_feature_names))\\nprint(\"Length tf features before removing high and low presence: %i \" %len(tf_feature_names))\\n\\ndef remove_presence(features, documents, min_presence = 0.05, max_presence = 0.95):\\n    docs_num = float(len(documents))\\n    for term in features:\\n        c = 0\\n        for doc in documents:\\n            c += int(term in doc)\\n        if (c > docs_num * max_presence) or (c < min_presence):\\n            features.remove(term)\\n    return features\\n\\ntfidf_feature_names = remove_presence(tfidf_feature_names, documents, min_presence = 0.05, max_presence = 0.6)\\nprint(\"Length tfidf features after removing high and low presence: %i \" % len(tfidf_feature_names))\\ntf_feature_names = remove_presence(tf_feature_names, documents, min_presence = 0.05, max_presence = 0.6)\\nprint(\"Length tf features after removing high and low presence: %i \" % len(tf_feature_names))\\n'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}